worker_processes auto;
events {
    worker_connections 4096;
}

http {
    # Release closed connections quickly so FDs don't pile up under load
    reset_timedout_connection on;

    # Cap concurrent connections so we return 503 (handled) instead of connection resets/5xx under overload
    limit_conn_zone $server_name zone=conn_total:10m;
    limit_conn_status 503;
    limit_conn_log_level warn;

    # Docker's embedded DNS; short TTL so --scale api=N is picked up
    resolver 127.0.0.11 valid=5s ipv6=off;

    server {
        listen 4000 backlog=4096;

        location / {
            # Variable forces runtime DNS resolution so "api" round-robins across scaled replicas (e.g. --scale api=4)
            set $backend "api:4000";
            proxy_pass http://$backend;

            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_socket_keepalive on;

            # Standard headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Trace-ID $http_x_trace_id;

            # Long timeouts under load so nginx doesn't close while API/upstream is slow (avoids "connection reset by peer")
            proxy_connect_timeout 30s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
            proxy_next_upstream error timeout http_502 http_503;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 10s;
        }
    }
}
